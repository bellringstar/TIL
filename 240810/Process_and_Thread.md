# 프로세스와 스레드의 개념

## 프로세스
프로세스는 실행 중인 프로그램의 인스턴스입니다.
1. 코드 세그먼트 (텍스트 섹션)
   - 실행 가능한 프로그램 코드가 저장된 영역입니다.
   - 읽기 전용으로 설정되어 있어 프로세스가 실수로 자신의 코드를 수정하는 것을 방지합니다.
   - Read-only
     - 보안: 프로그램의 실행 코드가 실수로 또는 악의적으로 수정되는 것을 방지합니다. 이는 프로그램의 무결성을 유지하는 데 필수적입니다.
     - 공유: 여러 프로세스가 동일한 프로그램을 실행할 때, 코드 세그먼트를 공유할 수 있습니다. 이는 메모리 사용을 크게 줄일 수 있습니다. 예를 들어, 여러 사용자가 동시에 웹 브라우저를 실행할 때, 각 인스턴스는 고유한 데이터를 가지지만 코드는 공유할 수 있습니다.
   - Position-Independent Code
     - 현대 운영체제에서는 코드 세그먼트를 위치 독립적으로 만듭니다.
     - 동적 로딩: 프로그램을 메모리의 어느 위치에나 로드할 수 있게 됩니다. 이는 메모리 관리를 더 유연하게 만들어 줍니다.
     - 주소 공간 배치 무작위화(ASLR): 보안을 강화하기 위해 코드 세그먼트를 메모리의 무작위 위치에 로드할 수 있습니다. 이는 버퍼 오버플로우 같은 공격을 어렵게 만듭니다.
   - 캐시 최적화
     - 코드 세그먼트는 일반적으로 연속적으로 실행되는 경향이 있습니다. 이러한 특성 때문에 다음과 같은 최적화가 가능합니다.
     - 명령어 캐시: CPU는 코드 세그먼트를 위한 별도 캐시(I-cache)를 가지고 있어, 명령어 fetch를 빠르게 수행할 수 있습니다.
     - 분기 예측: 코드의 실행 흐름을 예측하여 파이프라인 스톨을 줄일 수 있습니다.
   - 메모리 정렬
     - 코드 세그먼트는 대게 페이지 크기에 맞춰 정렬됩니다. (예: 4KB)
     - 메모리 보호: 페이지 단위로 접근 권한을 설정할 수 있어, 코드 영역을 효과적으로 보호할 수 있습니다.
     - 가상 메모리 관리: 페이지 단위의 스와핑을 효율적으로 수행할 수 있습니다.
2. 데이터 세그먼트
   - 전역 변수와 정적 변수가 저장되는 영역입니다.
   - 초기화된 데이터 섹션과 초기화되지 않은 데이터 섹션(BSS)으로 나뉩니다.
   - 초기화된 데이터 세그먼트 (.data)
     - 명시적으로 초기값이 지정된 전역 변수와 정적 변수를 저장합니다.
     - 프로그램이 시작될 때 이미 값이 설정되어 있습니다.
     - 읽기-쓰기가 가능한 영역입니다.
     - 동작 원리
       - 컴파일 시: 컴파일러는 초기화된 변수들의 값을 실행 파일에 포함합니다.
       - 프로그램 로딩 시: 운영체제는 이 값들을 메모리에 로드합니다.
       - 실행 중: 프로그램은 이 영역의 데이터를 읽고 수정할 수 있습니다.
   - 초기화되지 않은 데이터 세그먼트 (.bss - Block Started by Symbol)
     - 초기값이 명시적으로 지정되지 않은 전역 변수와 정적 변수를 저장합니다.
     - 프로그램 시작 시 모든 변수는 0 또는 null로 초기화됩니다.
     - 읽기-쓰기가 가능한 영역입니다.
     - 동작 원리
       - 컴파일 시: 컴파일러는 이 변수들의 크기 정보만 기록합니다. 값은 저장하지 않스니다.
       - 프로그램 로딩 시: 운영체제는 이 영역을 0으로 초기화합니다.
       - 실행 중: 프로그램은 이 영역의 데이터를 읽고 수정할 수 있습니다.
   - 데이터 세그먼트의 중요성
     - 메모리 효율성: .bss 세그먼트는 실행 파일의 크기를 줄입니다. 초기값이 0인 대량의 데이터를 파일에 저장할 필요가 없기 때문입니다.
     - 프로그램 생명주기: 데이터 세그먼트의 변수들은 프로그램의 전체 실행 기간 동안 존재합니다. 이는 전역 상태를 유지해야 하는 경우에 유용합니다.
     - 최적화: 컴파일러와 링커는 데이터 세그먼트를 최적화하여 메모리 접근 효율을 높일 수 있습니다.
     - 보안: 데이터 세그먼트는 읽기-쓰기가 가능하지만, 실행은 불가능하게 설정될 수 있습니다. 이는 일부 보안 공격을 방지하는 데 도움이 됩니다.
   - 데이터 세그먼트가 .data와 .bss로 나뉜 이유
     - 실행 파일 크기 최적화
       - .data: 초기값이 있는 변수들의 실제 값을 저장해야 하므로 실행 파일에 포함됩니다.
       - .bss: 초기화되지 않은 데이터는 값을 저장할 필요가 업서 실행 파일에 공간을 차지하지 않습니다. 단지 크기 정보만 저장합니다.
       - 예를 들어 1MB크기의 초기화되지 않은 배열이 있다고 하면 이를 .bss에 둠으로써, 실행 파일 크기를 1MB 줄일 수 있습니다.
     - 로딩 시간 최적화
       - .data 섹션: 프로그램 로딩 시 디스크에서 메모리로 값을 복사해야 합니다.
       - .bss 섹션: 단순히 메모리를 0으로 초기화하면 되므로, 디스크 I/O 없이 빠르게 설정할 수 있습니다.
     - 메모리 매핑 효율성
       - .bss 섹션은 실제로 물리적 메모리를 차지하지 않고, 필요할 때 'demand-zero' 페이지로 매핑됩니다. 이는 실제 메모리 사용을 지연시켜 시스템 자원을 효율적으로 사용할 수 있게 합니다.
     - 역사적 이유
       - 초기 컴퓨터 시스템에서는 메모리가 매우 제한적이었습니다. .bss 섹션을 따로 두어 실행 파일 크기를 줄이는 것이 중요했습니다.
     - 링커의 최적화
       - 분리된 섹션으로 인해 링커가 더 효율적으로 작동할 수 있습니다. 예를 들어, 여러 오브젝트 파일을 링크할 때 .bss 섹션들을 쉽게 병합할 수 있습니다.
     - 보안 강화
       - .data 와 .bss를 분리함으로써, 운영체제는 각 섹션에 대해 다른 메모리 보호 정책을 적용할 수 있습니다. 예를 들어, .data 섹션은 읽기 전용으로 설정할 수 있지만 .bss는 항상 쓰기 가능해야 합니다.
3. 힙
   - 동적으로 할당되는 메모리 영역입니다.
   - 주요 특징
     - 동적 할당
       - 프로그램 실행 중에 필요한 만큼 메모리를 할당하고 해제할 수 있습니다.
       - 컴파일 시점에 크기를 알 수 없는 데이터를 다룰 때 유용합니다.
     - 수명 관리
       - 프로그래머가 직접 메모리의 할당과 해제를 관리해야 합니다.
       - 메모리 누수나 댕글링 포인터(해제된 메모리를 가리키는 포인터) 같은 문제가 발생할 수 있습니다.
     - 크기의 유연성
       - 스택과 달리 힙은 필요에 따라 크기가 늘어나거나 줄어들 수 있습니다.
       - 스택
         - 스택도 크기가 변하긴 합니다. 함수 호출 시 증가하고 반환 시 감소합니다.
         - 그러나 이 변화는 매우 구조화되어 이쏙 예측 가능합니다. (LIFO)
         - 스택의 최대 크기는 일반적으로 프로그램 시작 시 고정됩니다. (예: Linux 기본값 8MB)
         - 스택 오버플로우가 발생하면 프로그램이 크래시됩니다.
       - 힙
         - 힙의 크기 변화는 더 동적이고 불규칙적입니다.
         - 프로그래머가 명시적으로 요청할 떄만 크기가 변합니다.
         - 힙의 최대 크기는 일반적으로 사용 간으한 가상 메모리에 의해서만 제한됩니다.
         - 메모리 할당 실패 시 NULL을 반환하므로, 프로그래머가 이를 처리할 수 있습니다.
       - 핵심 차이
         - 제어: 스택은 자동으로 관리되지만, 힙은 프로그래머가 직접 제어합니다.
         - 유연성: 힙은 불규칙한 크기의 블록을 할당/해제할 수 있지만, 스택은 항상 최상위 요소만 접근 가능합니다.
         - 힙의 데이터는 명시적으로 해제할 때까지 존재하지만, 스택의 데이터는 함수 종료오 함꼐 자동으로 소멸됩니다.
     - 속도
       - 스택에 비해 메모리 할당과 해제가 상대적으로 느립니다.
     - 단펴화
       - 지속적인 할당과 해제로 인해 메모리 단편화가 발생할 수 있습니다.
   - 동작 원리
     - 메모리 할당
       - 프로그램이 메모리를 요청하면 힙 관리자가 적절한 크기의 빈 공간을 찾아 할당합니다.
       - 할당된 메모리의 주소를 반환합니다.
     - 메모리 해제
       - 프로그래머가 더 이상 필요 없는 메모리를 해제합니다.
       - 해제된 메모리는 다시 사용 가능한 상태가 됩니다.
     - 메모리 관리 알고리즘
       - First Fit: 충분한 크기의 첫 번째 빈 공간을 사용
         - 장점
           - 검색 시간이 짧다. 적합한 첫 번째 공간을 찾으면 바로 할당한다.
           - 구현이 간단하다.
         - 단점
           - 메모리의 앞 부분에 작은 조각들이 쌓일 수 있다.
           - 이상적인 공간을 찾지 못할 수 있어 메모리 낭비가 발생할 수 있다.
       - Best Fit: 요청한 크기에 가장 근접한 빈 공간을 사용
         - 장점
           - 메모리 낭비 최소화
           - 큰 빈 공간을 보존하여 나중에 큰 메모리 요청을 수용할 수 있다.
         - 단점
           - 전체 힙을 검색해야 하므로 시간이 오래 걸릴 수 있다.
           - 작은 조각들이 많이 생길 수 있어 외부 단편화를 증가시킬 수 있다.
       - Worst Fit: 가장 큰 빈 공간을 사용
         - 장점
           - 큰 빈 공간을 분할하므로, 중간 크기의 요청을 수용하기 쉽습니다.
           - 작은 파편들의 생성을 줄일 수 있습니다.
         - 단점
           - 큰 빈 공간을 빠르게 소진할 수 있어 나중에 큰 메모리 요청을 수용하기 어려울 수 있습니다.
           - 전체 힙을 검색해야 하므로 시간이 오래 걸릴 수 있습니다.
       - 실제로는 이런 기본 알고리즘들의 변형이나 혼합을 사용합니다.
         - 분리 맞춤 (Segregated Fits)
           - 다양한 크기의 메모리 풀을 유지하여 빠른 할당을 가능하게 합니다.
           - 예: jemalloc, tcmalloc
         - 버디 시스템 (Buddy System)
           - 메모리를 2의 거듭제곱 크기로 관리하여 빠른 할당과 병합을 가능하게 합니다.
           - 리눅스 커널에서 사용됩니다.
         - Slab 할당자
           - 특정 크기의 객체를 효율적으로 할당하기 위해 설계됩니다.
           - 많은 운영 체제 커널에서 사용됩니다.
   - 힙이 왜 필요한가
     - 데이터의 수명 관리: 스택의 데이터는 함수 호출과 함께 생성되고 함수가 종료되면 자동으로 소멸됩니다. 그러나 이는 함수의 생명주기를 벗어나는 데이터를 다루기 어렵게 만듭니다.
     - 런타임 메모리 요구 사항: 프로그램이 실행 중에 얼마나 많은 메모리가 필요할지 미리 알 수 없는 경우가 많습니다. 사용자 입력이나 외부 데이터에 따라 메모리 요구사항이 달라질 수 있습니다. 
     - 대규모 데이터 구조: 스택은 일반적으로 크기가 제한되어 있어(보통 몇 MB), 대규모 데이터 구조를 다루기 어렵습니다. 힙은 이론적으로는 가용 메모리 전체를 사용할 수 있습니다.
4. 스택
   - 함수 호출 시 지역 변수, 매개변수, 반환 주소 등이 저장되는 영역입니다.
   - 함수 호출과 반환에 따라 크기가 동적으로 변합니다.
   - LIFO (Last In First Out) 구조로 작동합니다.
   - 주요 특징
     - 자동 메모리 관리
       - 함수 호출 시 자동으로 메모리가 할당되고, 함수 종료 시 자동으로 해제됩니다.
       - 프로그래머가 명시적으로 메모리를 관리할 필요가 없습니다.
     - 빠른 접근 속도
       - 스택 포인터(SP)를 사용하여 최상위 요소에 빠르게 접근할 수 있습니다.
       - 메모리 할당 및 해제가 단순한 포인터 조작으로 이루어져 매우 빠릅니다.
     - 제한된 크기
       - 일반적으로 프로그램 시작 시 크기가 고정됩니다 (예: Linux에서 기본 8MB)
       - 스택 오버플로우가 발생할 수 있습니다.
     - 지역 변수 및 함수 호출 정보 저장
       - 각 함수 호출마다 스택 프레임이 생성됩니다.
       - 지역 변수, 매개변수, 반환 주소 등을 저장합니다.
   - 구조와 동작 원리
     - 스택 프레임: 각 함수 호출마다 생성되며 다음 정보를 포함합니다.
       - 지역 변수
       - 매개변수
       - 반환 주소
       - 이전 스택 프레임에 대한 포인터(EBP)
     - 스택 포인터(SP)
       - 스택의 최상위 요소를 가리킵니다.
       - 함수 호출 시 감소하고, 함수 반환 시 증가합니다.(스택이 높은 주소에서 낮은 주소로 자람)
     - 베이스 포인터(BP)
       - 현재 스택 프레임의 기준점을 가리킵니다.
       - 지역 변수와 매개변수에 쉽게 접근할 수 있게 해줍니다.
   - 장단점
     - 장점
       - 빠른 메모리 할당 및 해제
       - 자동 메모리 관리로 인한 편리성
       - 함수 호출과 반환의 효율적인 구현
     - 단점
       - 크기 제한으로 인핸 스택 오버플로우 가능성
       - 동적 크기 조절의 어려움
       - 데이터의 수명이 함수의 수명에 종속됨
   - 필요한 이유
     - 함수 호출 메커니즘
       - 함수 호출 시 현재 실행 지점을 저장하고, 함수 종료 후 돌아올 위치를 기억해야 합니다.
       - 스택은 이러한 정보를 효율적으로 관리할 수 있는 구조를 제공합니다.
     - 지역 변수의 효율적인 관리
       - 함수마다 독립적인 지역 변수 공간이 필요합니다.
       - 스택은 함수 호출과 함께 자동으로 이 공간을 할당하고 해제합니다.
     - 재귀 함수 지원
       - 각 재귀 호출마다 새로운 스택 프레임이 생성되어 ,함수의 여러 인스턴스가 동시에 존재할 수 있습니다.
     - 컨텍스트 스위칭의 효율성
       - 멀티태스킹 환경에서 프로세스나 스레드 간 전환 시, 현재 실행 상태를 빠르게 저장하고 복원할 수 있습니다.

## 프로세스의 상태
1. New
   - 프로세스가 생성되어 메모리에 적재되었지만, 아직 실행을 위한 초기화가 완료되지 않은 상태입니다.
   - 이 상태에서 운영체제는 프로세스에 필요한 자원을 할당하고, PCB를 생성합니다.
2. Ready
   - 프로세스가 실행될 준비가 완료된 상태입니다.
   - CPU 할당을 기다리는 상태로, 준비 큐에서 대기합니다.
   - 스케줄러의 결정에 따라 실행 상태로 전환될 수 있습니다.
3. Running
   - 프로세스가 CPU를 할당받아 실제로 실행 중인 상태입니다.
   - 단일 코어 시스템에서는 한 번에 하나의 프로세스만 이 상태에 있을 수 있습니다.
   - 시간 할당량이 끝나거나, 인터럽트가 발생하면 준비 상태로 돌아갑니다.
4. Waiting
   - 프로세스가 특정 이벤트(예: I/O 완료, 시그널 수신)를 기다리는 상태입니다.
   - 이 상태의 프로세스는 CPU를 사용하지 않으며, 대기 큐에 있습니다.
   - 기다리던 이벤트가 발생하면 준비 상태로 전환됩니다.
5. Terminated
   - 프로세스 실행이 완료되어 시스템에서 제거될 준비가 된 상태입니다.
   - 이 상태에서 운영체제는 프로세스가 사용하던 자원을 회수합니다.

프로세스 상태 전이
1. New -> Ready: 프로세스 생성 완료
2. Ready -> Running: 스케줄러가 CPU 할당
3. Running -> Ready: 시간 할당량 소진 또는 우선순위가 높은 프로세스 등장
4. Running -> Waiting: I/O 요청 또는 이벤트 대기
5. Waiting -> Ready: 대기 중이던 이벤트 발생
6. Running -> Terminated: 프로세스 실행 완료 또는 오류로 인한 종료

워드프로세서를 실행하는 과정을 프로세스 상태 변화로 설명해보겠습니다.
1. 사용자가 워드 프로세서 실행 -> New 상태 (프로레스 생성)
2. 초기화 완료 -> Ready 상태 (실행 준비)
3. CPU 할당받음 -> Running 상태 (사용자 입력 처리 중)
4. 파일 저장 버튼 클릭 -> Waiting 상태 (디스크 I/O 대기)
5. 저장 완료 -> Ready 상태 (다시 실행 준비)
6. 다시 CPU 할당받음 -> Running 상태 (계속 실행)
7. 사용자 종료 -> Terminated (프로세스 종료)

### 위 예시에서 키보드 입력도 실제 I/O 작업의 한 형태인데 키가 입력될 때 마다 대기상태로 전환될까?

워드 프로세서의 동작 방식과 운영체제의 I/O 처리 메커니즘을 고려할 때, 키 입력마다 프로세스가 대기 상태로 전환되지는 않습니다.
1. 입력 처리 메커니즘
   - 인터럽트 기반 입력 처리
     - 키보드 입력은 일반적으로 인터럽트 기반으로 처리됩니다.
     - 키를 누르면 하드웨어 인터럽트가 발생하고, 운영체제의 인터럽트 핸들러가 이를 처리합니다.
     - 이 과정은 매우 빠르게 이루어지며, 프로세스를 대기 상태로 전환할 만큼 오래 걸리지 않습니다.
   - 버퍼링
     - 키보드 입력은 보통 커널의 버퍼에 저장됩니다.
     - 프로세스는 이 버퍼에서 데이터를 읽어오며, 버퍼가 비어있을 때만 대기 상태로 전환될 수 있습니다.
2. 비차단 I/O와 이벤트 기반 프로그래밍
   - 현대의 많은 애플리케이션은 비차단 I/O와 이벤트 기반 프로그래밍 모델을 사용합니다.
   - 이 모델에서는 I/O 작업이 즉시 완료되지 않더라도 프로세스가 차단되지 않습니다.
   - 대신, I/O 준비 상태를 주기적으로 확인하거나 (폴링) 이벤트 통지를 받아 처리합니다.
3. 시스테 콜과 사용자 공간 전환
   - 키보드 입력을 읽는 작업은 시스템 콜을 통해 이루어집니다.(예: read())
   - 그러나 이 시스템 콜은 보통 버퍼에 데이터가 있을 때만 호출되므로, 매 키 입력마다 호출되지 않습니다.
4. 성능과 효율성 고려
   - 매 키 입력마다 프로세스를 대기 상태로 전환하는 것은 시스템 자원을 비효율적으로 사용하게 됩니다.
   - 컨텍스트 스위칭의 오버헤드가 키 입력 처리 시간보다 더 클 수 있습니다.

추가 고려사항
1. 멀티스레딩: 현대의 많은 애플리케이션은 멀티스레드로 구현됩니다. 이 경우, 입력 처리, UI 갱신, 백그라운드 작업 등이 별도의 스레드로 실행될 수 있습니다.
참고로 현대 운영체제에서는 스케줄링의 기본 단위가 스레드입니다. 따라서 프로세스의 "Running" 상태는 해당 프로세스의 적어도 하나의 스레드가 CPU를 사용 중임을 의미합니다.
2. 이벤트 드리븐 아키텍처: GUI 애플리케이션은 주로 이벤트 드리븐 방식으로 동작합니다. 이는 프로세스가 지속적으로 Running 상태를 유지하면서 이벤트를 처리하는 방식입니다.
3. 실시간 시스템: 일부 실시간 시스템에서는 입력 처리의 우선순위가 매우 높아 별도의 처리 메커니즘을 사용할 수 있습니다.

이러한 프로세스 상태 관리는 왜 중요할까요?
1. 리소스 효율성: CPU와 같은 중요 자원을 효율적으로 사용할 수 있습니다.
2. 동시성 지원: 여러 프로세스를 동시에 실행하는 것처럼 보이게 합니다.
3. 응답성 향상: 대기 상태를 통해 I/O 작업 중에도 다른 프로세스가 실행될 수 있게 합니다.
4. 스케줄링 최적화: 각 상태에 있는 프로세스의 특성을 고려해 효율적인 스케쥴링 가능하빈다.


### 비차단 I/O와 차단 I/O의 차이점은 무엇이며, 각각 어떤 상황에서 유용할까요?
1. 차단 I/O (Blocking I/O)
   - 정의
     - I/O 작업이 완료될 때까지 프로세스(또는 스레드)가 대기 상태로 들어가는 방식입니다.
     - 작업이 완료되면 결과와 함께 제어가 반환됩니다.
   - 특징
     - 간단하고 직관적인 프로그래밍 모델을 제공합니다.
     - I/O 작업 중에는 CPU를 사용하지 않습니다.
     - 동시에 여러 I/O 작업을 처리하기 어렵습니다.
   - 유용한 상황
     - 단순한 클라이언트 애플리케이션
     - I/O 작업이 빠르게 완료되는 경우
     - 멀티스레딩을 통해 병렬 처리가 가능한 경우
     - 리소스가 제한된 환경에서 CPU 사용을 최고화해야 할 때
   - ```java
     try (BufferedReader reader = new BufferedReader(new FileReader("file.txt"))) {
        String line = reader.readLine(); // 이 호출은 차단됩니다.
        System.out.println(line);
     } catch (IOException e) {
        e.printStackTrace();
     }
     ```
2. 비차단 I/O (Non-Blocking I/O)
   - 정의
     - I/O 작업을 요청한 후 즉시 제어가 반환되는 방식입니다.
     - 작업의 완료 여부는 나중에 확인하거나 통지를 받습니다.
   - 특징
     - 복잡한 프로그래밍 모델이지만, 높은 동시성을 제공합니다.
     - I/O 작업 중에도 다른 작업을 수행할 수 있습니다.
     - 많은 수의 동시 연결을 효율적으로 처리할 수 있습니다.
     - CPU 사용률이 높아질 수 있습니다 (특히 폴링 방식을 사용할 경우)
   - 유용한 상황
     - 고성능 네트워크 서버 (예: 웹 서버, 게임 서버)
     - 실시간 시스템
     - 이벤트 기반 아키텍처
     - 많은 I/O 작업을 동시에 처리해야 하는 경우
   - ```java
     // Java NIO
     try (FileChannle channel = FileChannel.open(Paths.get("file.txt"), StandardOpenOption.READ)) {
        ByteBuffer buffer = ByteBuffer.allocate(1024);
        int bytesRead = channel.read(buffer);
        if (bytesRead > 0) {
            buffer.flip();
            System.out.println(StandardCharsets.UTF_8.decode(buffer));
        }
     } catch (IOException e) {
        e.printStackTrace();
     }
     ```
3. 비교 및 선택 기준
   - 성능
     - 차단 I/O: 단순한 작업에 적합, 동시성이 낮음
     - 비차단 I/O: 복잡한 시스템에 적합, 높은 동시성 제공
   - 복잡성
     - 차단: 구현과 이해가 쉬움
     - 비차단: 복잡한 로직 필요, 에러 처리가 어려울 수 있음
   - 리소스 사용
     - 차단: 스레드 리소스를 많이 사용할 수 있음
     - 비차단: 적은 수의 스레드로 많은 연결 처리 가능
4. 실제 적용 시나리오
   - 웹 서버
     - 비차단 I/O를 사용하여 수천 개의 동시 연결을 효율적으로 처리
     - 예: Nginx, Node.js
   - 데이터베이스 클라이언트
     - 차단 I/O를 사용하여 간단한 쿼리 실행
     - 비차단 I/O를 사용하여 대량의 비동기 쿼리 처리
   - 파일 처리 유틸리티
     - 차단 I/O를 사용하여 간단하고 직관적인 코드 작성
   - 실시간 채팅 애플리케이션
     - 비차단 I/O를 사용하여 많은 사용자의 메시지를 동시에 처리

### 비차단 I/O를 사용할 때 발생할 수 있는 문제점들은 무엇이며, 어떻게 해결할 수 있을까요?
1. 복잡성 증가
   - 문제
     - 비차단 I/O는 전통적인 순차적 프로그래밍 모델과 다르기 때문에 코드가 복잡해질 수 있습니다.
     - 콜백 지옥이 발생할 수 있으며, 에러 처리가 어려워질 수 있습니다.
   - 해결 방안
     - 비동기 프로그래밍 패턴 사용
       - Promise/Future 패턴
       - Reactive Programming(예: RxJava, Project Reactor)
       - async/await (JavaScript, C#, Kotlin..)
       - ```java
         CompletableFuture<String> future = CompletableFuture.suppliyAsync(() -> readFromFile())
            .thenApply(content -> processContent(content))
            .thenApply(result -> saveToDatabase(result));
         
         future.thenAccept(System.out::println)
               .exceptionally(ex -> {
                   System.err.println("An error occurred: " + ex.getMessage);
                   return null;
               })
         ```
     - 상태 기계 패턴 사용
       - 복잡한 비동기 로직을 관리 가능한 상태로 분리
     - 코드 구조화 및 모듈화
       - 비동기 작업을 작은 단위로 분리하고 조합
2. 리소스 관리의 어려움
   - 문제
     - 비차단 I/O는 리소스를 더 오랫동안 열어둘 수 있어, 리소스 누수의 위험이 있습니다.
     - 동시에 많은 연결을 처리할 때 메모리 사용량이 급증할 수 있습니다.
   - 해결 방안
     - 리소스 풀링
       - 연결 풀, 버퍼 풀 등을 사용하여 리소스 재사용
     - 타임아웃 메커니즘
       - 장기 실행 작업에 대한 타임아웃 설정
     - 백프레셔 구현
       - 시스템이 처리할 수 있는 양보다 더 많은 요청이 들어올 때 제어
     - ```java
       // NIO with Timeout
       Selector selector = Selector.open();
       channel.configureBlocking(false);
       SelectionKey key = channel.register(selector, SelectionKey,OP_READ);
       
       while (true) {
           if (selector.select(timeout) == 0) {
               System.out.println("Operation timed out");
               break;
           }
       }
       ```
3. 디버깅의 어려움
   - 문제
     - 비동기 실행 흐름은 추적하기 어려울 수 있습니다.
     - 스택 트레이스가 의미 있는 정보를 제공하지 않을 수 있습니다.
   - 해결 방안
     - 로깅 강화: 비동기 작업의 각 단계마다 상세한 로그 기록
     - 분산 추적 시스템 사용: 예) Zipkin, Jaeger
     - 비동기 aware 디버깅 도구 사용: 예) IntelliJ IDEA의 Async 스택 트레이스
     - 상관 ID 사용: 각 요청에 고유 ID를 할당하여 전체 처리 과정 추적
4. 오류 전파 및 처리
   - 문제
     - 비동기 작업에서 발생한 오류가 적절히 전파되지 않을 수 있습니다.
     - 전역 예외 처리기가 비동기 작업의 예외를 잡지 못할 수 있습니다.
   - 해결 방안
     - 오류 콜백 사용
       - 각 비동기 작업에 오류 처리 콜백 추가
     - 모나드 패턴 사용
       - 예: Optional, Either 타입을 사용하여 오류 상태 표현
     - 전용 예외 처리 미들웨어 구현
       - 비동기 작업의 예외를 중앙에서 처리
5. 순서 보장의 어려움
   - 문제
     - 비차단 I/O에서는 작업의 완료 순서가 시작 순서와 다를 수 있습니다.
     - 이는 데이터 일관성 문제를 일으킬 수 있습니다.
   - 해결 방안
     - 작업 체이닝: Promise 체인이나 CompletableFuture의 thenApply() 등을 사용
     - 동기화 지점 사용: 여러 비동기 작업의 결과를 모아서 처리
     - 순서 보장 메커니즘 구현: 시퀀스 번호나 타임스탬프를 사용하여 순서 추적

### 비차단 I/O를 사용하는 시스템에서 성능 테스트를 어떻게 효과적으로 수행할 수 있을까요?
### 비차단 I/O와 마이크로서비스 아키텍처를 함께 사용할 때 고려해야 할 특별한 점은 무엇이 있을까요?
### 비차단 I/O를 사용하는 시스템에서 트랜잭션 관리는 어떻게 해야 할까요?
### 차단 I/O와 비차단 I/O를 함께 사용하는 하이브리드 접근 방식의 장단점은 무엇일까요?
### 비차단 I/O를 효과적으로 사용하기 위해 어떤 디자인 패턴이나 라이브러리를 활용할 수 있을까요?
### 비동기 I/O를 사용할 때, 스레드와 프로세스의 상태 변화는 어떻게 다를까요?

### 이벤트 드리븐 아키텍처가 전통적인 폴링 방식에 비해 갖는 장점은 무엇일까요?
### 멀티코어 시스템에서 워드 포르세서와 같은 애플리케이션의 성능을 최적화하려면 어떤 방식으로 설계해야 할까요?
### 멀티코어 시스템에서는 Running 상태의 프로세스가 동시에 여러 개 존재할 수 있을까요?
### 모든 스레드가 동시에 I/O 대기 상태가 되면 프로세스의 상태는 어떻게 될까요?
### 스레드 풀을 사용하는 것이 프로세스 전반적인 상태 관리에 어떤 영향을 미칠까요?
### 프로세스가 Waiting 상태에서 직접 Running 상태로 갈 수 없는 이유는 무엇일까요?
### 시분할 시스템에서 Running -> Ready 전이가 자주 일어나는 이유는 무엇일까요?

## 프로세스 제어 블록 (PCB)
각 프로세스는 운영체제에 의해 PCB라는 자료구조로 표현됩니다. PCB에는 다음과 같은 정보가 포함됩니다.
- 프로세스 ID
  - 각 프로세스의 고유 식별 번호
- 프로세스 상태
- 프로그램 카운터 (다음에 실행할 명령어 주소)
- CPU 레지스터
  - 누산기, 인덱스 레지스터, 스택 포인터 등
  - 컨텍스트 스위칭 시 저장 및 복원됨
- CPU 스케줄링 정보
  - 프로세스 우선순위, 스케줄링 큐 포인터 등
- 메모리 관리 정보
  - 베이스 레지스터, 한계 레지스터 값
  - 페이지 테이블 또는 세그먼트 테이블에 대한 포인터
- 입출력 상태 정보
- 계정 정보

PCB의 역할과 중요성
1. 프로세스 관리
   - 운영체제가 프로세스의 상태를 추적하고 관리할 수 있게 함
2. 컨텍스트 스위칭
   - CPU가 다른 프로세스로 전환할 때, 현재 프로세스의 상태를 PCB에 저장하고 새 프로세스의 상태를 PCB에 로드
3. 프로세스 스케줄링
   - 스케줄러가 PCB 정보를 기반으로 다음에 실행할 프로세스를 결정
4. 리소스 할당
   - 프로세스에 필요한 리소스 정보를 관리
5. 프로세스 동기화 및 통신
   - 프로세스 간 통신에 필요한 정보 저장

### PCB가 메모리에서 어떻게 관리되는지 생각해볼 수 있을까요?
#### PCB 관리 방식이 시스템 성능에 어떤 영향을 미칠 수 있을까요?
#### 대규모 서버 시스템에서 수천 개의 프로세스를 관리할 때 PCB 구조를 어떻게 최적화할 수 있을까요?
#### 가상 환경(예: 컨테이너)에서 PCB 관리는 어떤 차이점이 있을까요?
### 멀티코어 시스템에서 PCB 관리는 어떤 차이가 있을까요?
#### CPU 친화성과 캐시 친화성 사이의 트레이드오프는 무엇이며, 어떻게 균형을 맞출 수 있을까요?
#### NUMA 아키텍처에서 PCB 관리 전략이 어떻게 시스템의 메모리 접근 패턴을 최적화할 수 있을까요?
### PCB의 크기가 프로세스 성능에 어떠 영향을 미칠 수 있을까요?
#### 시스템의 전체 프로세스 수가 PCB 크기 선택에 어떤 영향을 미칠까요?
#### 실시간 시스템에서 PCB 크기가 갖는 중요성은 일반 시스템과 어떻게 다를까요?
#### 가상화 환경(예: 컨테이너, 가상 머신)에서 PCB 크기가 성능에 미치는 영향은 어떻게 달라질 수 있을까요?